# 2026-1-28 created

# ä½¿ç”¨AIè¿›è¡Œæ©ç†™market_radaræŠ“å–çš„å­—å…¸

# äººæ°”é¢è‚¡ç¥¨ ä¸ æ”¿ç­–ï¼Œæ–°é—»çš„ç¢°æ’

import pandas as pd
import os
import pickle
from datetime import datetime
import math
import json


class StrategyScanner:
    def __init__(self, intel_data, linker, agent, db_client):
        """
        :param intel_data: MarketRadar æŠ“å–çš„å­—å…¸æ•°æ®
        :param linker: å·²ç» load_linker() è¿‡çš„ IndustryLinker å®ä¾‹
        """
        self.intel = intel_data
        self.linker = linker
        self.agent = agent
        self.db = db_client
        self.decay_lambda = 0.005  # æ—¶é—´è¡°å‡ç³»æ•°ï¼Œæ•°å€¼è¶Šå¤§è¡°å‡è¶Šå¿«

    def scan(self):
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ§  å¯åŠ¨ V2.0 è”æƒ³è®°å¿†æ‰«ææ¨¡å¼...")

        # 1. ä»æ•°æ®åº“æå–â€œæ´»è·ƒåˆ©å¥½æ± â€
        raw_intelligence = self.db.get_active_intelligence()
        if not raw_intelligence:
            print("ğŸ“­ è®°å¿†åº“ä¸­æš‚æ— æ´»è·ƒåˆ©å¥½ï¼Œæœ¬æ¬¡æ‰«æç»“æŸã€‚")
            return pd.DataFrame()

        # 2. é¢„å¤„ç†åˆ©å¥½ï¼ˆè®¡ç®—æ—¶é—´è¡°å‡ï¼‰
        active_sectors = self._process_active_sectors(raw_intelligence)

        # 3. è·å–å®æ—¶äººæ°”æ¦œ
        popularity_df = self.intel.get('äººæ°”é¢', pd.DataFrame())
        if popularity_df.empty:
            print("âš ï¸ æœªè·å–åˆ°å®æ—¶äººæ°”æ¦œï¼Œæ— æ³•å®Œæˆå…±æŒ¯ã€‚")
            return pd.DataFrame()

        # 4. æ‰§è¡Œå…±æŒ¯äº¤å‰åŒ¹é…
        return self._cross_resonance(active_sectors, popularity_df)

    def _process_active_sectors(self, raw_data):
        """
        æ ¸å¿ƒé€»è¾‘ï¼šå°†å¤šæ¡æ–°é—»çš„åˆ©å¥½å åŠ ï¼Œå¹¶æ ¹æ®æ—¶é—´è¡°å‡
        è¿”å›æ ¼å¼: { "æ¿å—å": {"total_score": 150, "reasons": [...] } }
        """
        sector_pool = {}
        for title, ai_score, sectors_json, pub_date, source, age_hours in raw_data:
            sectors = json.loads(sectors_json)

            # æ—¶é—´è¡°å‡å…¬å¼: Score * e^(-Î» * t)
            # æ”¿ç­–ç±»è¡°å‡æ…¢ï¼Œå¿«è®¯ç±»è¡°å‡å¿«
            lambda_val = 0.002 if source == 'policy' else 0.02
            decay_factor = math.exp(-lambda_val * age_hours)
            adjusted_score = ai_score * decay_factor

            for s_name, _ in sectors.items():
                if s_name not in sector_pool:
                    sector_pool[s_name] = {"total_score": 0, "reasons": [], "max_score": 0}

                sector_pool[s_name]["total_score"] += adjusted_score
                sector_pool[s_name]["max_score"] = max(sector_pool[s_name]["max_score"], adjusted_score)
                sector_pool[s_name]["reasons"].append(f"({source}){title[:10]}")

        return sector_pool

    def _cross_resonance(self, sector_pool, popularity_df):
        """
        å°†æ¿å—æ± ä¸äººæ°”æ¦œè¿›è¡Œæ’å‡»
        """
        candidates = []
        # ç¡®ä¿åˆ—åå¯¹é½
        pop_col = 'ä»£ç ' if 'ä»£ç ' in popularity_df.columns else popularity_df.columns[0]
        popularity_df['short_code'] = popularity_df[pop_col].astype(str).str.extract(r'(\d{6})')

        for s_name, info in sector_pool.items():
            # æ¨¡ç³ŠåŒ¹é…æ¿å—ä¸ªè‚¡
            sector_stocks = self._get_stocks_by_sector_name(s_name)
            if not sector_stocks: continue

            # å–äº¤é›†
            matched = popularity_df[popularity_df['short_code'].isin(sector_stocks)]

            for _, stock in matched.iterrows():
                # ç»¼åˆåˆ† = å†å²åˆ©å¥½å åŠ åˆ† + (100 - äººæ°”æ’å)
                # æ’åè¶Šé å‰ï¼ˆindexè¶Šå°ï¼‰ï¼Œçƒ­åº¦è¶Šé«˜
                market_hot = (100 - stock.name)  # å‡è®¾äººæ°”æ¦œç»™äº†100å
                final_score = info['total_score'] + market_hot

                candidates.append({
                    "ä»£ç ": stock['short_code'],
                    "åç§°": stock['åç§°'] if 'åç§°' in stock else "æœªçŸ¥",
                    "é©±åŠ¨èµ›é“": s_name,
                    "ç»¼åˆå¼ºåº¦": round(final_score, 2),
                    "é€»è¾‘æ”¯æ’‘": " | ".join(list(set(info['reasons']))[:2]),  # å–å‰ä¸¤ä¸ªç†ç”±
                    "çƒ­åº¦æ¥æº": "æ”¿ç­–è®°å¿†+å®æ—¶äººæ°”" if info['max_score'] > 50 else "çŸ­çº¿è„‰å†²"
                })

        result_df = pd.DataFrame(candidates)
        if not result_df.empty:
            # å»é‡ï¼šå¦‚æœä¸€å°è‚¡ç¥¨è¢«å¤šä¸ªæ¿å—å‘½ä¸­ï¼Œä¿ç•™åˆ†æ•°æœ€é«˜çš„
            result_df = result_df.sort_values('ç»¼åˆå¼ºåº¦', ascending=False).drop_duplicates('ä»£ç ')
        return result_df

    def _get_stocks_by_sector_name(self, name):
        """
        å‡çº§ç‰ˆï¼šæ”¯æŒæ¨¡ç³ŠåŒ¹é…çš„è¾…åŠ©å‡½æ•°
        ç­–ç•¥ï¼š1. å…ˆè¯•ç²¾å‡†åŒ¹é… 2. å¤±è´¥åå°è¯•å…³é”®è¯åŒ…å«åŒ¹é… 3. å¤±è´¥åå°è¯•ç®€åŒ–åŒ¹é…
        """
        # æå‰åŠ è½½å­—å…¸ï¼ˆå»ºè®®åœ¨ __init__ ä¸­åŠ è½½ä¸€æ¬¡ï¼Œé¿å…é¢‘ç¹è¯»å– pklï¼‰
        ind_map = pd.read_pickle(self.linker.industry_file)
        cp_map = pd.read_pickle(self.linker.concept_file)
        all_sectors = {**ind_map, **cp_map}

        # 1. ç¬¬ä¸€é˜¶æ®µï¼šç²¾å‡†åŒ¹é… (æœ€å¿«)
        if name in all_sectors:
            return all_sectors[name]

        # 2. ç¬¬äºŒé˜¶æ®µï¼šæ¨¡ç³ŠåŒ…å«é€»è¾‘
        # æ¯”å¦‚ AI ç»™çš„æ˜¯ "äººå·¥æ™ºèƒ½"ï¼Œå­—å…¸é‡Œæ˜¯ "äººå·¥æ™ºèƒ½æ¦‚å¿µ"ï¼Œè¿™æ—¶å€™ in æ“ä½œç¬¦ç«‹åŠŸ
        matches = []
        for sector_key, stocks in all_sectors.items():
            if name in sector_key or sector_key in name:
                matches.extend(stocks)

        if matches:
            return list(set(matches))  # å»é‡

        # 3. ç¬¬ä¸‰é˜¶æ®µï¼šå…³é”®è¯é™ç»´ (å…œåº•)
        # æ¯”å¦‚ "åŠå¯¼ä½“æ¦‚å¿µ" -> å˜æˆ "åŠå¯¼ä½“" å†æœä¸€é
        clean_name = name.replace("æ¦‚å¿µ", "").replace("æ¿å—", "").replace("è¡Œä¸š", "")
        if clean_name != name:
            for sector_key, stocks in all_sectors.items():
                if clean_name in sector_key:
                    matches.extend(stocks)

        return list(set(matches))

    def _align_sector_names(self, ai_sector_name):
        """
        å°† AI è¿”å›çš„è¡Œä¸šåæ˜ å°„åˆ°ä¸œè´¢å®˜æ–¹è¡Œä¸šå
        """
        # è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å¯¹é½å­—å…¸ï¼Œä»¥åå¯ä»¥æ ¹æ®æŠ¥é”™æ—¥å¿—ä¸æ–­è¡¥å……
        ALIGN_MAP = {
            "èŠ¯ç‰‡": "åŠå¯¼ä½“",
            "é›†æˆç”µè·¯": "åŠå¯¼ä½“",
            "é£è¡Œæ±½è½¦": "èˆªå¤©èˆªç©º",
            "æ— äººæœº": "èˆªå¤©èˆªç©º",
            "ç™½é…’": "é…¿é…’è¡Œä¸š",
            "AI": "è®¡ç®—æœºè®¾å¤‡"
        }

        # 1. ç›´æ¥åŒ¹é…
        if ai_sector_name in self.linker.industry_map:
            return ai_sector_name

        # 2. åˆ«ååŒ¹é…
        return ALIGN_MAP.get(ai_sector_name, None)


    # def scan_version1(self):
    #     """
    #     æ‰«æç­–ç•¥ï¼šå¯»æ‰¾â€˜æ”¿ç­–/çƒ­æœâ€™ä¸â€˜çƒ­é—¨æ¿å—â€™çš„å…±æŒ¯
    #     """
    #     candidates = []
    #
    #     # 1. æå–æ”¿ç­–é¢å’Œçƒ­æœé¢çš„å…³é”®è¯
    #     # å®é™…å¼€å‘ä¸­ï¼Œè¿™é‡Œå¯ä»¥æ¥å…¥ LLM æå–ï¼Œç°åœ¨æˆ‘ä»¬ç”¨ç®€å•çš„åŒ…å«åŒ¹é…
    #     policy_titles = " ".join(self.intel['æ”¿ç­–é¢']['æ”¿ç­–æ ‡é¢˜'].tolist())
    #     hot_search_topics = " ".join(self.intel['äººæ°”é¢']['è‚¡ç¥¨åç§°'].head(10).tolist())  # å‰10äººæ°”è‚¡å
    #
    #
    #     # 2. è·å–å½“å‰æœ€å¼ºçš„å‰ 10 ä¸ªæ¿å— (æ¥è‡ªæ¿å—é¢æ•°æ®)
    #     hot_sectors_df = self.intel['æ¿å—é¢'].head(10)
    #
    #     print(f"ğŸ” æ­£åœ¨æ‰«æå…±æŒ¯ä¿¡å·...")
    #
    #     for _, sector_row in hot_sectors_df.iterrows():
    #         sector_name = sector_row['æ¿å—åç§°']
    #
    #         # åˆ¤æ–­é€»è¾‘ï¼šå¦‚æœçƒ­é—¨æ¿å—åç§°å‡ºç°åœ¨æ”¿ç­–æ–°é—»ä¸­ï¼Œè®¤ä¸ºè¯¥èµ›é“è¢«ç‚¹ç«
    #         # ä¾‹å¦‚ï¼šæ–°é—»æœ‰â€œåŠå¯¼ä½“â€ï¼Œæ¿å—é‡Œåˆšå¥½æœ‰â€œåŠå¯¼ä½“â€
    #         if sector_name in policy_titles or any(keyword in sector_name for keyword in ["è‡ªä¸»å¯æ§", "é«˜æ–°"]):
    #             print(f"ğŸ”¥ å‘ç°èµ›é“å…±æŒ¯: {sector_name}")
    #
    #             # ä» linker ä¸­è·å–è¯¥æ¿å—çš„æ‰€æœ‰ä¸ªè‚¡
    #             # æ³¨æ„ï¼šIndustryLinker é‡Œçš„ industry_map å’Œ concept_map å·²ç»åˆå¹¶åœ¨ stock_to_tags é‡Œäº†
    #             # è¿™é‡Œæˆ‘ä»¬ç›´æ¥æ ¹æ®æ¿å—åç§°åå‘æå–
    #             sector_stocks = self._get_stocks_by_sector_name(sector_name)
    #
    #             # 3. ä¸â€œäººæ°”ä¸ªè‚¡â€æ±‚äº¤é›†ï¼Œæ‰¾å‡ºè¯¥æ¿å—é‡Œçš„é¢†æ¶¨é¾™å¤´
    #             popularity_stocks = self.intel['äººæ°”é¢']['ä»£ç '].tolist()
    #             print(f"è°ƒè¯•ï¼šå½“å‰äººæ°”è‚¡ç¤ºä¾‹: {popularity_stocks[:3]}")  # æŸ¥çœ‹æ ¼å¼
    #
    #
    #             clean_popularity_stocks = [code[-6:] for code in popularity_stocks]
    #             leader_stocks = list(set(sector_stocks) & set(clean_popularity_stocks))
    #
    #             # åœ¨å¾ªç¯å†…éƒ¨
    #             if sector_name in policy_titles:
    #                 sector_stocks = self._get_stocks_by_sector_name(sector_name)
    #                 clean_popularity_stocks = [code[-6:] for code in popularity_stocks]
    #                 print(f"è°ƒè¯•ï¼šåŒ¹é…åˆ°æ¿å— {sector_name}ï¼ŒåŒ…å«è‚¡ç¥¨æ•°: {len(sector_stocks)}")
    #                 # æ‰“å°ä¸€ä¸‹äº¤é›†å‰çš„æ¯”å¯¹
    #                 leader_stocks = list(set(sector_stocks) & set(clean_popularity_stocks))
    #                 print(f"è°ƒè¯•ï¼šäº¤é›†ç»“æœæ•°: {len(leader_stocks)}")
    #
    #             for code in leader_stocks:
    #                 name = self.intel['äººæ°”é¢'].loc[self.intel['äººæ°”é¢']['ä»£ç '] == code, 'åç§°'].values[0]
    #                 candidates.append({
    #                     "ä»£ç ": code,
    #                     "åç§°": name,
    #                     "èµ›é“": sector_name,
    #                     "æ¨èç†ç”±": f"æ”¿ç­–å…±æŒ¯ + æ¿å—èµ°å¼º({sector_row['æ¶¨è·Œå¹…']}%) + äººæ°”å‰æ’"
    #                 })
    #
    #     return pd.DataFrame(candidates)

    # def scan(self):
    #     print("ğŸ§  æ­£åœ¨å¯åŠ¨å¤šç»´è”åˆå…±æŒ¯æ‰«æ...")
    #
    #     # --- ç¬¬ä¸€æ­¥ï¼šä»æ•°æ®åº“æ‹‰å–â€œè”åˆåˆ©å¥½æ± â€ ---
    #     # æˆ‘ä»¬ä¸å†ä¾èµ– self.intel['æ”¿ç­–é¢']ï¼Œå› ä¸ºé‚£æ˜¯â€œæ–°å¢â€ï¼Œæˆ‘ä»¬è¦çœ‹çš„æ˜¯â€œæœ‰æ•ˆæœŸå†…â€çš„æ‰€æœ‰åˆ©å¥½
    #     # è·å–è¿‡å» 7 å¤©ï¼Œè¯„åˆ†å¤§äº 70 çš„æ‰€æœ‰æ–°é—»ï¼ˆåŒ…å«æ”¿ç­–å’Œå¿«è®¯ï¼‰
    #     high_value_news = self.db.get_recent_high_value_news(days=7, min_score=70)
    #
    #     if not high_value_news:
    #         print("âš ï¸ æ•°æ®åº“ä¸­è¿‘æœŸæ— é«˜åˆ†åˆ©å¥½ï¼Œè·³è¿‡è¯­ä¹‰åˆ†æã€‚")
    #         return pd.DataFrame()
    #
    #     # å°†æ•°æ®åº“è®°å½•è½¬ä¸ºå¯å¤„ç†çš„æ ¼å¼
    #     # æ•°æ®åº“å­—æ®µé¡ºåºï¼š0:title, 1:ai_score, 2:sectors_json, 3:pub_date, 4:source
    #     combined_news = []
    #     for item in high_value_news:
    #         try:
    #             combined_news.append({
    #                 "title": item[0],
    #                 "score": item[1],
    #                 "sectors": json.loads(item[2]),
    #                 "date": item[3],
    #                 "type": item[4]
    #             })
    #         except:
    #             continue
    #
    #     # --- ç¬¬äºŒæ­¥ï¼šå‡†å¤‡äººæ°”æ¦œæ•°æ® ---
    #     candidates = []
    #     if 'äººæ°”é¢' not in self.intel or self.intel['äººæ°”é¢'].empty:
    #         print("âŒ ç¼ºå¤±äººæ°”æ¦œæ•°æ®ï¼Œæ— æ³•è¿›è¡Œå…±æŒ¯ã€‚")
    #         return pd.DataFrame()
    #
    #     popularity_df = self.intel['äººæ°”é¢'].copy()
    #     # ç»Ÿä¸€ä»£ç æ ¼å¼ï¼Œç¡®ä¿èƒ½å’Œæ˜ å°„è¡¨åŒ¹é…
    #     popularity_df['short_code'] = popularity_df['ä»£ç '].astype(str).str.extract(r'(\d{6})')
    #
    #     # --- ç¬¬ä¸‰æ­¥ï¼šå…±æŒ¯åŒ¹é… (Cross-Resonance) ---
    #     print(f"ğŸ” æ­£åœ¨å¯¹ {len(combined_news)} æ¡æœ‰æ•ˆåˆ©å¥½è¿›è¡Œæ¿å—ç©¿é€...")
    #
    #     for news in combined_news:
    #         news_title = news['title']
    #         sectors_data = news['sectors']  # è¿™æ˜¯ä¸€ä¸ª {æ¿å—å: åˆ†æ•°} çš„å­—å…¸
    #
    #         for s_name, sector_score in sectors_data.items():
    #             # ä½¿ç”¨æˆ‘ä»¬ä¹‹å‰å†™çš„æ¨¡ç³ŠåŒ¹é…å‡½æ•°è·å–ä¸ªè‚¡
    #             sector_stocks = self._get_stocks_by_sector_name(s_name)
    #
    #             # å¯»æ‰¾äººæ°”è‚¡äº¤é›†
    #             matched = popularity_df[popularity_df['short_code'].isin(sector_stocks)]
    #
    #             for _, stock in matched.iterrows():
    #                 # ç»¼åˆçƒ­åº¦ç®—æ³•ï¼šAIåˆ† + äººæ°”åŠ æƒ
    #                 # å¯ä»¥åŠ å…¥æ—¶é—´è¡°å‡ï¼šå¦‚æœæ˜¯å‡ å¤©å‰çš„æ”¿ç­–ï¼Œæƒé‡ç¨å¾®é™ä½
    #                 total_score = sector_score + (20 - stock.name)
    #
    #                 candidates.append({
    #                     "ä»£ç ": stock['short_code'],
    #                     "åç§°": stock.get('åç§°') or stock.get('è‚¡ç¥¨åç§°'),
    #                     "èµ›é“": s_name,
    #                     "ç»¼åˆçƒ­åº¦": total_score,
    #                     "æ¨èç†ç”±": f"[{news['type']}] {news_title[:15]}...",
    #                     "å‘ç°æ—¶é—´": news['date']
    #                 })
    #
    #     # --- ç¬¬å››æ­¥ï¼šå»é‡ä¸æ’åº ---
    #     df_result = pd.DataFrame(candidates)
    #     if not df_result.empty:
    #         # å¦‚æœåŒä¸€åªè‚¡ç¥¨å‘½ä¸­å¤šä¸ªæ¿å—ï¼Œå–æœ€é«˜åˆ†é‚£ä¸ª
    #         df_result = df_result.sort_values(by="ç»¼åˆçƒ­åº¦", ascending=False)
    #         df_result = df_result.drop_duplicates(subset=['ä»£ç '], keep='first')
    #
    #     return df_result