# market_radar.py
# ç”¨äºæ•´åˆä¸åŒç½‘ç«™çš„å®æ—¶ä¿¡æ¯
from python_quant.harvesters.akshare_harvesters import QuantDataHarvester
from python_quant.scrapers.gov_cn_scrapers import GovernmentPolicyScraper
from datetime import datetime
import pandas as pd
from utils.db_helper import QuantumDB
from python_quant.logic_layer.analyst_agent import AnalystAgent
import time


class MarketRadar:
    """
    ä¸­å°ç±»ï¼šè´Ÿè´£æ•´åˆå…¨å¸‚åœºçš„â€˜é¢â€™æ•°æ®ï¼ˆå¿«è®¯ã€æ¿å—ã€äººæ°”ã€ç ”æŠ¥ã€çƒ­æœã€æ”¿ç­–ï¼‰
    """

    def __init__(self):
        self.harvester = QuantDataHarvester()
        self.policy_scraper = GovernmentPolicyScraper()
        self.db_client = QuantumDB()
        self.agent = AnalystAgent()  # æ–°å¢ï¼šç”¨äºé¢„åˆ†ææ–°é—»



    def get_full_intelligence(self):
        print(f"[{datetime.now().strftime('%H:%M:%S')}] æ­£åœ¨æ‰§è¡Œå…¨ç»´åº¦å¸‚åœºæ‰«æ...")

        # 1. è·å–åŸå§‹æ•°æ®åŒ…
        intel = self.harvester.get_all_raw_data()
        policy_df = self.policy_scraper.get_news_df()

        # 2. å¤„ç†æ”¿ç­–é¢ï¼šå»é‡ -> åˆ†æ -> å…¥åº“
        if not policy_df.empty:
            print("âš–ï¸ æ­£åœ¨å¤„ç†æ”¿åºœæ”¿ç­–...")

            # å…¥åº“å‰é‡å‘½åï¼Œå¯¹é½æ•°æ®åº“å­—æ®µ (pub_date, title, source)
            policy_df = policy_df.rename(columns={'å‘å¸ƒæ—¥æœŸ': 'pub_date', 'æ”¿ç­–æ ‡é¢˜': 'title', 'è¯¦æƒ…é“¾æ¥':'link_url'})

            # ç›´æ¥æŠŠçˆ¬åˆ°çš„ 1000 æ¡å¾€åº“é‡Œå¡ï¼Œsave_news_batch å†…éƒ¨çš„ INSERT OR IGNORE ä¼šè‡ªåŠ¨å»é‡
            self.db_client.save_news_batch(policy_df, source_type='policy')

            # æ‰¾å‡ºåº“é‡Œæœ€è¿‘ä¸€å¹´ã€ä¸” ai_score=0 çš„æ–°æ”¿ç­–
            pending_policies = self.db_client.get_pending_news(days=365, source_type='policy')

            if not pending_policies.empty:
                print(f"âœ¨ å‘ç° {len(pending_policies)} æ¡æ–°æ”¿ç­–ï¼Œè¯·æ±‚ AI æ‰¹é‡åˆ†æ...")
                # è°ƒç”¨ä½ æä¾›çš„åˆ†æå‡½æ•°
                self._analyze_and_store(pending_policies, 'title', 'policy')
            else:
                print("æ”¿ç­–åº“æ— æ‰“åˆ†æ–°é—»")

            intel["æ”¿ç­–é¢"] = self.db_client.get_today_analyzed_news('policy')

        # 3. å¤„ç†å¿«è®¯é¢ï¼šå»é‡ -> åˆ†æ -> å…¥åº“
        flash_df = intel.get("å¿«è®¯é¢", pd.DataFrame())
        if not flash_df.empty:
            print("ğŸ“° æ­£åœ¨å¤„ç†å®æ—¶å¿«è®¯...")

            # æ ¸å¿ƒä¿®å¤ 2ï¼šå¿«è®¯é€šå¸¸å†…å®¹å‚å·®ä¸é½ï¼Œå¿…é¡»æ¸…æ´—
            # å‡è®¾å¿«è®¯å¯¹åº”çš„åˆ—ååœ¨ DataFrame é‡Œå« 'title' æˆ– 'content'
            # df[["å‘å¸ƒæ—¶é—´", "æ ‡é¢˜", "å†…å®¹"]]
            print("ğŸ“° æ­£åœ¨å¤„ç†å®æ—¶å¿«è®¯...")
            flash_df = flash_df.rename(columns={'æ ‡é¢˜': 'title', 'å‘å¸ƒæ—¶é—´': 'pub_date','å†…å®¹':'content'})
            self.db_client.save_news_batch(flash_df, source_type='flash')

            pending_flash = self.db_client.get_pending_news(days=3, source_type='flash')
            if not pending_flash.empty:
                self._analyze_and_store(pending_flash, 'title', 'flash')

            intel["å¿«è®¯é¢"] = self.db_client.get_today_analyzed_news('flash')

        return intel

    def _filter_new_items(self, df, col_name, source_type):
        """
        é’ˆå¯¹æ€§å»é‡ï¼š
        - å¦‚æœæ˜¯ policyï¼šå¯¹æ¯”åº“ä¸­æ‰€æœ‰å†å²æ”¿ç­–ã€‚
        - å¦‚æœæ˜¯ flashï¼šåªå¯¹æ¯”åº“ä¸­æœ€è¿‘ 30 å¤©çš„å¿«è®¯ã€‚
        """
        cursor = self.db_client.conn.cursor()

        if source_type == 'policy':
            # æ”¿ç­–ç±»ï¼šå…¨é‡æå–æ ‡é¢˜
            cursor.execute("SELECT title FROM news_items WHERE source='policy'")
        else:
            # å¿«è®¯ç±»ï¼šåªæå–æœ€è¿‘30å¤©çš„æ ‡é¢˜
            cursor.execute("""
                SELECT title FROM news_items 
                WHERE source='flash' 
                AND created_at > datetime('now', '-30 days')
            """)

        existing_titles = set(res[0] for res in cursor.fetchall())

        # è¿”å›ä¸åœ¨åº“ä¸­çš„æ–°é²œæ–°é—»
        return df[~df[col_name].isin(existing_titles)]



    def _analyze_and_store(self, df, col_name, source_type):
        """è°ƒç”¨ AI åˆ†æå¹¶æ›´æ–°æ•°æ®åº“ä¸­çš„è¯„åˆ†"""
        if df.empty:
            return df
        titles = df[col_name].tolist()

        # 1. æ‰¹é‡è°ƒç”¨ AI ä»£ç†
        # analysis_results æ ¼å¼: {æ ‡é¢˜: {'score': 90, 'sectors': [...]}}
        chunk_size = 15

        for i in range(0, len(titles), chunk_size):
            chunk = titles[i: i + chunk_size]
            print(f" - æ­£åœ¨åˆ†æç¬¬ {i // chunk_size + 1} ç»„æ•°æ® ({len(chunk)} æ¡)...")

            try:
                # æ‰¹é‡è°ƒç”¨ AI
                analysis_results = self.agent.batch_analyze(chunk)

                # æ›´æ–°æ•°æ®åº“
                for title in chunk:
                    analysis = analysis_results.get(title)
                    if analysis:
                        if analysis['score'] == 0:
                            analysis['score'] = 1
                        self.db_client.update_news_score(
                            title=title,
                            score=analysis['score'],
                            sectors=analysis['sectors']
                        )
                        if analysis['score'] >= 85:
                            self.db_client.record_strategy_hit(title, analysis['sectors'])

                # ç¨å¾®åœé¡¿ä¸€ä¸‹ï¼Œé˜²æ­¢ API é™åˆ¶é¢‘ç‡
                time.sleep(1)

            except Exception as e:
                print(f"âŒ è¿™ä¸€ç»„ AI åˆ†æå¤±è´¥: {e}")
                continue  # è¿™ä¸€ç»„å¤±è´¥äº†è·³è¿‡ï¼Œä¸å½±å“åé¢

        return df



    def format_to_text(self, intel, top_n=10):
        """å°†æ•°æ®å­—å…¸è½¬åŒ–ä¸ºæ˜“è¯»çš„ Markdown æ–‡æœ¬ï¼ˆä¸º LLM å‡†å¤‡ï¼‰"""
        output = [f"# å¸‚åœºå…¨æ™¯æ‰«ææŠ¥å‘Š ({datetime.now().strftime('%Y-%m-%d %H:%M')})\n"]

        # å®šä¹‰å±•ç¤ºé¡ºåºå’Œæ ‡é¢˜æ˜ å°„
        mapping = {
            "å¿«è®¯é¢": "ğŸ“° å®æ—¶å¿«è®¯ (è´¢è”ç¤¾)",
            "æ¿å—é¢": "ğŸ”¥ çƒ­é—¨èµ›é“ (æ¿å—è¡Œæƒ…)",
            "äººæ°”é¢": "ğŸ“ˆ å¸‚åœºäººæ°”ä¸ªè‚¡",
            "ç ”æŠ¥é¢": "ğŸ’¡ æœºæ„ç ”æŠ¥å…±è¯†",
            "çƒ­æœé¢": "ğŸ” é¢˜æçƒ­æœå…³é”®è¯",
            "æ”¿ç­–é¢": "âš–ï¸ æ”¿åºœæœ€æ–°æ”¿ç­–"
        }
        # é’ˆå¯¹ä¸åŒç»´åº¦ï¼Œé€‰æ‹©ä¸åŒçš„æ•æ„Ÿåº¦, top_n ä½œä¸ºé™åˆ¶
        limits = {
            "å¿«è®¯é¢": 15,  # å¿«è®¯å¤šä¸€ç‚¹ï¼Œæ–¹ä¾¿ LLM æ‰¾å…³è”
            "æ¿å—é¢": 8,  # èµ›é“ä¸éœ€è¦å¤ªå¤šï¼Œåªçœ‹æœ€çƒ­çš„
            "äººæ°”é¢": 10,
            "ç ”æŠ¥é¢": 10,
            "çƒ­æœé¢": 5,  # å…³é”®è¯åªè¦æœ€ç«çš„å‡ ä¸ª
            "æ”¿ç­–é¢": 10
        }
        for key, title in mapping.items():
            if key in intel and not intel[key].empty:
                limit = limits.get(key, top_n)  # è·å–è‡ªå®šä¹‰é™åˆ¶ï¼Œé»˜è®¤ç”¨ top_n
                output.append(f"## {title}")
                output.append(intel[key].head(limit).to_markdown(index=False))

        return "\n".join(output)


if __name__ == "__main__":
    # å•ç‹¬æµ‹è¯• Radar æ¨¡å—
    radar = MarketRadar()
    print("ğŸš€ å¼€å§‹è¿è¡Œå¸‚åœºé›·è¾¾æµ‹è¯•...")
    start_time = datetime.now()
    data = radar.get_full_intelligence()
    # text = radar.format_to_text(data)
    # print(text)
    # --- éªŒè¯é€»è¾‘ ---
    print("\n" + "=" * 30)
    print("ğŸ“Š è¿è¡Œç»“æœéªŒè¯ï¼š")

    for key in ["æ”¿ç­–é¢", "å¿«è®¯é¢"]:
        df = data[key]
        print(f"\n[{key}] æ¨¡å—:")
        print(f" - æ€»è®¡å¯ç”¨æƒ…æŠ¥æ•°: {len(df)} æ¡")

        if not df.empty:
            # éªŒè¯åˆ†æ•°æ˜¯å¦éƒ½å·²æ‰“ä¸Š
            zero_scores = df[df['ai_score'] == 0]
            if zero_scores.empty:
                print(f" âœ… æˆåŠŸï¼šæ‰€æœ‰æ•°æ®å‡å·²æ‰“åˆ†ã€‚")
            else:
                print(f" âŒ è­¦å‘Šï¼šä»æœ‰ {len(zero_scores)} æ¡æ•°æ®æœªæ‰“åˆ†ã€‚")

            # éªŒè¯é«˜åˆ†åˆ†å¸ƒ
            high_score_count = len(df[df['ai_score'] >= 80])
            print(f" - å‘ç°é«˜ä»·å€¼æƒ…æŠ¥ (>=80åˆ†): {high_score_count} æ¡")

            # æ‰“å°æœ€æ–°çš„ä¸€æ¡çœ‹çœ‹
            print(f" - æœ€æ–°æƒ…æŠ¥æ ·ä¾‹: {df.iloc[0]['æ”¿ç­–æ ‡é¢˜'][:30]}...")
        else:
            print(" âš ï¸ æç¤ºï¼šä»Šæ—¥æ— æ–°å¢æˆ–æœ‰æ•ˆæƒ…æŠ¥ã€‚")

    end_time = datetime.now()
    print("\n" + "=" * 30)
    print(f"â±ï¸ æ€»è€—æ—¶: {end_time - start_time}")
    print("âœ… æµ‹è¯•ç»“æŸã€‚æ•°æ®å·²åŒæ­¥è‡³æ•°æ®åº“ã€‚")